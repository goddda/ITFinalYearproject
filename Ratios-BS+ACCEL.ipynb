{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Importing libraries and defining the set low_obs</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from scipy.stats import kurtosis\n",
    "%matplotlib notebook\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random as rn\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "from statistics import mode, median    \n",
    "from scipy.integrate import simps\n",
    "from math import floor\n",
    "\n",
    "low_obs = ['0.1quant_accel_x_ins', \n",
    "'0.1quant_accel_y', \n",
    "'0.1quant_accel_z_ins',  \n",
    "'0.25quant_accel_x_ins',  \n",
    "'0.25quant_accel_y',  \n",
    "'0.25quant_accel_z_ins',  \n",
    "'0.75quant_accel_y',  \n",
    "'0.75quant_accel_z_ins',  \n",
    "'0.9quant_accel_y_exp',  \n",
    "'0.9quant_accel_z_ins',  \n",
    "'max_accel_y',  \n",
    "'mean_accel_y',  \n",
    "'mean_accel_x_ins',  \n",
    "'mean_accel_z_ins',  \n",
    "'median_accel_x_ins',  \n",
    "'median_accel_y',  \n",
    "'median_accel_z_ins',  \n",
    "'min_accel_x_ins',  \n",
    "'min_accel_y',  \n",
    "'min_accel_z_ins']  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Functions for calculating the features</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMeans(df):\n",
    "    df = df.mean()\n",
    "    m = pd.DataFrame(\n",
    "        data=[df]\n",
    "    )\n",
    "    m.columns = ['mean']\n",
    "    return m\n",
    "\n",
    "def findStd(df):\n",
    "    df = df.std()\n",
    "    m = pd.DataFrame(\n",
    "        data = [df]\n",
    "    )\n",
    "    m.columns = ['std']\n",
    "    return m\n",
    "\n",
    "def toMin(df):\n",
    "    mini = df.min()\n",
    "    mean = df.mean()\n",
    "    tomin = pd.DataFrame(\n",
    "        data=[mini - mean]\n",
    "    )\n",
    "    tomin.columns = ['min-mean']\n",
    "    return tomin\n",
    "\n",
    "def toMax(df):\n",
    "    maxi = df.max()\n",
    "    mean = df.mean()\n",
    "    tomax = pd.DataFrame(\n",
    "        data=[maxi - mean]\n",
    "    )\n",
    "    tomax.columns = ['max-mean']\n",
    "    return tomax\n",
    "\n",
    "def findMin(df):\n",
    "    mini = df.min()\n",
    "    tomin = pd.DataFrame(\n",
    "        data=[mini]\n",
    "    )\n",
    "    tomin.columns = ['min']\n",
    "    return tomin\n",
    "\n",
    "def findMax(df):\n",
    "    maxi = df.max()\n",
    "    tomax = pd.DataFrame(\n",
    "        data=[maxi]\n",
    "    )\n",
    "    tomax.columns = ['max']\n",
    "    return tomax\n",
    "\n",
    "def rangea(df):\n",
    "    maxi = df.max()\n",
    "    mini = df.min()\n",
    "    rangea = pd.DataFrame(\n",
    "        data=[maxi - mini]\n",
    "    )\n",
    "    rangea.columns = ['range']\n",
    "    return rangea\n",
    "\n",
    "def skewa(df):\n",
    "    s = pd.DataFrame(\n",
    "        data=[df.skew()]\n",
    "    )\n",
    "    s.columns = ['skewness']\n",
    "    return s\n",
    "\n",
    "def findMedians(df):\n",
    "    df = df.median()\n",
    "    m = pd.DataFrame(\n",
    "        data=[df]\n",
    "    )\n",
    "    m.columns = ['median']\n",
    "    return m\n",
    "\n",
    "def findKurtosis(df):\n",
    "    df = kurtosis(df)\n",
    "    m = pd.DataFrame(\n",
    "        data=[df]\n",
    "    )\n",
    "    m.columns = ['kurtosis']\n",
    "    return m\n",
    "\n",
    "def findQuantiles(df, perc):\n",
    "    df = df.quantile(perc)\n",
    "    m = pd.DataFrame(\n",
    "        data=[df]\n",
    "    )\n",
    "    m.columns = [str(perc) + 'quant']\n",
    "    return m\n",
    "\n",
    "def findMeanCrossCount(df):\n",
    "    peak_list = []\n",
    "    df = df.values\n",
    "    means = df.mean()\n",
    "    \n",
    "    peak_list = []\n",
    "    for i, value in enumerate(df):\n",
    "        if i < 1:\n",
    "            continue\n",
    "        if value <= means and df[i-1] >= means:\n",
    "            peak_list.append(i)\n",
    "        elif value >= means and df[i-1] <= means:\n",
    "            peak_list.append(i)\n",
    "    m = pd.DataFrame(\n",
    "                data=[len(peak_list)]\n",
    "    )\n",
    "    m.columns = ['mean_cross']\n",
    "    return m\n",
    "\n",
    "def findPeaks(df):\n",
    "    peaks, _ = signal.find_peaks(df.T.values[0])\n",
    "    m = pd.DataFrame(\n",
    "        data=[len(peaks)]\n",
    "    )\n",
    "    m.columns = ['peaks']\n",
    "    m.reset_index(drop=True)\n",
    "    return m\n",
    "\n",
    "def findLength(df):\n",
    "    df = df.shape[0]\n",
    "    m = pd.DataFrame(\n",
    "        data=[df]\n",
    "    )\n",
    "    m.columns = ['length']\n",
    "    return m\n",
    "\n",
    "def findLengthRatio(df, df1):\n",
    "    df = df.shape[0]\n",
    "    df1 = df1.shape[0]\n",
    "    m = pd.DataFrame(\n",
    "        data=[df/df1]\n",
    "    )\n",
    "    m.columns = ['lengthRatio']\n",
    "    return m\n",
    "\n",
    "def findArea(df):\n",
    "    area = simps(df.T.values[0])\n",
    "    m = pd.DataFrame(\n",
    "        data=[area]\n",
    "    )\n",
    "    m.columns = ['area']\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Reading the data and getting features for inspiration, expirations and full breaths of 3 accelerometer values and the breathing signal</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the features and appending to the main \"features\" dataframe\n",
    "def getFeatures(df):\n",
    "    features = []\n",
    "    features.append(findMeans(df))\n",
    "    features.append(findStd(df))\n",
    "    features.append(toMax(df))\n",
    "    features.append(toMin(df))\n",
    "    features.append(findMax(df))\n",
    "    features.append(findMin(df))\n",
    "    features.append(rangea(df))\n",
    "    features.append(skewa(df))\n",
    "    features.append(findMedians(df))\n",
    "    features.append(findKurtosis(df))\n",
    "    features.append(findQuantiles(df, 0.1).reset_index(drop=True)) \n",
    "    features.append(findQuantiles(df, 0.9).reset_index(drop=True))\n",
    "    features.append(findQuantiles(df, 0.25).reset_index(drop=True))\n",
    "    features.append(findQuantiles(df, 0.75).reset_index(drop=True)) \n",
    "    features.append(findMeanCrossCount(df))\n",
    "    features.append(findPeaks(df))\n",
    "    features.append(findLength(df))\n",
    "    features.append(findArea(df))\n",
    "    all_features = pd.concat(features, axis=1, sort=False)\n",
    "    return all_features\n",
    "\n",
    "def load_data_from_csv_in_dir(path, files=None, plot=False):\n",
    "    accel_all, bs_all, start_ind_all, end_ind_all, Y, end_ind_all, features_all, features_all_exp, can_all = [], [], [], [], [], [], [], [], []\n",
    "    features_all_accel_x_ins, features_all_accel_y_ins, features_all_accel_z_ins = [], [], []\n",
    "    features_all_accel_x_exp, features_all_accel_y_exp, features_all_accel_z_exp = [], [], []\n",
    "    patients = []\n",
    "    count = 0\n",
    "    if files is None:\n",
    "        files = os.listdir(path)\n",
    "    for i, file in enumerate(files):\n",
    "        if (file[-4:] == \".csv\"):\n",
    "        \n",
    "            df = pd.read_csv(path + file)\n",
    "            patient = int(re.findall(r'\\d+', file)[0])\n",
    "            patients.append(patient)\n",
    "            if patient!=1:\n",
    "                continue\n",
    "            if plot==True:\n",
    "                count += 1\n",
    "                plt.figure(count)\n",
    "                plt.title(\"Patient %d\" % patient)\n",
    "                plt.tight_layout()\n",
    "       \n",
    "            start, end, obstr, normal = df[\"14 Memory\"].values, df[\"15 Memory\"].values, df[\"17 Memory\"].values, df[\"16 Memory\"].values\n",
    "            start_ind = np.where(start == 1)[0]\n",
    "            end_ind = np.where(end == 1)[0]\n",
    "            accel = df[['accel_x', 'accel_y','accel_z']]/-16384\n",
    "            accel = ((accel - accel.min())/(accel.max()-accel.min()))\n",
    "            bs = df['breath_signal']\n",
    "            bs = pd.DataFrame(bs)\n",
    "            bs = ((bs - bs.min())/(bs.max()-bs.min()))\n",
    "\n",
    "#             accel = accel.rolling(5).mean()\n",
    "\n",
    "            can = df[\"Cannula\"]\n",
    "            can = ((can - can.min())/(can.max()-can.min()))*(0.5-(-0.0))+(-0.0)\n",
    "            \n",
    "            accel_pat, bs_pat, Y_pat, features_pat, features_pat_ins, features_pat_exp, can_pat = [], [], [], [], [], [], []\n",
    "            features_pat_accel_x, features_pat_accel_y, features_pat_accel_z = [], [], [] \n",
    "            features_pat_accel_x_ins, features_pat_accel_y_ins, features_pat_accel_z_ins = [], [], []\n",
    "            features_pat_accel_x_exp, features_pat_accel_y_exp, features_pat_accel_z_exp = [], [], []\n",
    "\n",
    "            e = 0\n",
    "            for i in range(len(start_ind) - 1):\n",
    "                if(start_ind[i] > end_ind[e]): e += 1\n",
    "                if(start_ind[i+1] < end_ind[e]): e -= 1\n",
    "          \n",
    "                if (start_ind[i] != end_ind[e]):\n",
    "                    pre_breath=start_ind[i]\n",
    "                    post_breath = end_ind[e]\n",
    "                    if(len(bs.iloc[start_ind[i]:start_ind[i+1]]) <= 300 \n",
    "                       and len(bs.iloc[start_ind[i]:end_ind[e]]) >= 10\n",
    "                       and len(bs.iloc[end_ind[e]:start_ind[i+1]]) >= 10\n",
    "#                        Patient 1 removed periods:\n",
    "#                        and start_ind[i] < 600000\n",
    "#                        and (start_ind[i] < 106000 or start_ind[i] > 106900)\n",
    "#                        and (start_ind[i] < 296400 or start_ind[i] > 310400)\n",
    "#                        and (start_ind[i] < 354700 or start_ind[i] > 356620)\n",
    "#                        and (start_ind[i] < 103900 or start_ind[i] > 104300)\n",
    "#                        and (start_ind[i] < 454427 or start_ind[i] > 454732)\n",
    "#                        and (start_ind[i] < 451059 or start_ind[i] > 451191)\n",
    "                      ):\n",
    "                        if (sum(obstr[pre_breath:post_breath]) >= 1 or sum(normal[pre_breath:post_breath]) >= 1):\n",
    "                            accel_pat.append(accel[start_ind[i]:start_ind[i+1]])\n",
    "                            can_pat.append(can[start_ind[i]:start_ind[i+1]])\n",
    "                            bs_pat.append(bs[start_ind[i]:start_ind[i+1]])\n",
    "                            #Insp\n",
    "                            features = getFeatures(bs.iloc[start_ind[i]:end_ind[e]+1])\n",
    "                            length_ratio = findLengthRatio(bs.iloc[start_ind[i]:end_ind[e]+1], bs.iloc[end_ind[e]:start_ind[i+1]+1])\n",
    "                            features = pd.concat([features, length_ratio], axis=1)\n",
    "                            features_pat_ins.append(features)\n",
    "                            \n",
    "                            #Concating the length ratio\n",
    "                            features = getFeatures(pd.DataFrame(accel['accel_x'].iloc[start_ind[i]:end_ind[e]+1]))\n",
    "                            length_ratio = findLengthRatio(pd.DataFrame(accel['accel_x'].iloc[start_ind[i]:end_ind[e]+1]), pd.DataFrame(accel['accel_x'].iloc[end_ind[e]:start_ind[i+1]+1]))\n",
    "                            features = pd.concat([features, length_ratio], axis=1)\n",
    "                            features_pat_accel_x_ins.append(features)\n",
    "\n",
    "                            features = getFeatures(pd.DataFrame(accel['accel_y'].iloc[start_ind[i]:end_ind[e]+1]))\n",
    "                            length_ratio = findLengthRatio(pd.DataFrame(accel['accel_y'].iloc[start_ind[i]:end_ind[e]+1]), pd.DataFrame(accel['accel_y'].iloc[end_ind[e]:start_ind[i+1]+1]))\n",
    "                            features = pd.concat([features, length_ratio], axis=1)\n",
    "                            features_pat_accel_y_ins.append(features)\n",
    "\n",
    "                            features = getFeatures(pd.DataFrame(accel['accel_z'].iloc[start_ind[i]:end_ind[e]+1]))\n",
    "                            length_ratio = findLengthRatio(pd.DataFrame(accel['accel_z'].iloc[start_ind[i]:end_ind[e]+1]), pd.DataFrame(accel['accel_z'].iloc[end_ind[e]:start_ind[i+1]+1]))\n",
    "                            features = pd.concat([features, length_ratio], axis=1)\n",
    "                            features_pat_accel_z_ins.append(features)\n",
    "\n",
    "                            #Exp\n",
    "                            features_pat_exp.append(getFeatures(bs.iloc[end_ind[e]:start_ind[i+1]+1]))\n",
    "                            features_pat_accel_x_exp.append(getFeatures(pd.DataFrame(accel['accel_x'].iloc[end_ind[e]:start_ind[i+1]+1])))\n",
    "                            features_pat_accel_y_exp.append(getFeatures(pd.DataFrame(accel['accel_y'].iloc[end_ind[e]:start_ind[i+1]+1])))\n",
    "                            features_pat_accel_z_exp.append(getFeatures(pd.DataFrame(accel['accel_z'].iloc[end_ind[e]:start_ind[i+1]+1])))\n",
    "\n",
    "                            #Full\n",
    "                            features_pat.append(getFeatures(bs.iloc[start_ind[i]:start_ind[i+1]+1]))\n",
    "                            features_pat_accel_x.append(getFeatures(pd.DataFrame(accel['accel_x'].iloc[start_ind[i]:start_ind[i+1]+1])))\n",
    "                            features_pat_accel_y.append(getFeatures(pd.DataFrame(accel['accel_y'].iloc[start_ind[i]:start_ind[i+1]+1])))\n",
    "                            features_pat_accel_z.append(getFeatures(pd.DataFrame(accel['accel_z'].iloc[start_ind[i]:start_ind[i+1]+1])))\n",
    "                        if (sum(obstr[pre_breath:post_breath]) >= 1):\n",
    "                            plt.plot(bs.iloc[start_ind[i]:end_ind[e]+1], '-r')\n",
    "                            plt.plot(bs.iloc[end_ind[e]:start_ind[i+1]]-0.2, '-r')\n",
    "                            plt.plot(bs.iloc[start_ind[i]:start_ind[i+1]]-0.8, '-r')\n",
    "#                             plt.plot(can.iloc[start_ind[i]:start_ind[i+1]+1], '-r')\n",
    "                            Y_pat.append(1)\n",
    "                        elif (sum(normal[pre_breath:post_breath]) >= 1):\n",
    "                        \n",
    "                            plt.plot(bs.iloc[start_ind[i]:end_ind[e]+1], '-g')\n",
    "                            plt.plot(bs.iloc[end_ind[e]:start_ind[i+1]]-0.2, '-g')\n",
    "                            plt.plot(bs.iloc[start_ind[i]:start_ind[i+1]]-0.8, '-g')\n",
    "#                             plt.plot(can.iloc[start_ind[i]:start_ind[i+1]+1], '-g')\n",
    "                            Y_pat.append(0)\n",
    "                e += 1\n",
    "            \n",
    "            start_ind_all.append(start_ind)\n",
    "            end_ind_all.append(end_ind)\n",
    "            bs_all.append(bs_pat)\n",
    "            accel_all.append(accel_pat)\n",
    "            Y.append(Y_pat)\n",
    "            can_all.append(can_pat)\n",
    "            \n",
    "            insp = pd.concat(features_pat_ins, ignore_index=True)\n",
    "            insp.columns = [str(col) + '_ins' for col in insp.columns]\n",
    "            exp = pd.concat(features_pat_exp, ignore_index=True)\n",
    "            exp.columns = [str(col) + '_exp' for col in exp.columns]\n",
    "            all_breath = pd.concat(features_pat, ignore_index=True)\n",
    "            \n",
    "            insp_accel_x = pd.concat(features_pat_accel_x_ins, ignore_index=True)\n",
    "            insp_accel_x.columns = [str(col) + '_accel_x_ins' for col in insp_accel_x.columns]\n",
    "            exp_accel_x = pd.concat(features_pat_accel_x_exp, ignore_index=True)\n",
    "            exp_accel_x.columns = [str(col) + '_accel_x_exp' for col in exp_accel_x.columns]\n",
    "            all_breath_accel_x = pd.concat(features_pat_accel_x, ignore_index=True)\n",
    "            all_breath_accel_x.columns = [str(col) + '_accel_x' for col in all_breath_accel_x.columns]\n",
    "            \n",
    "            insp_accel_y = pd.concat(features_pat_accel_y_ins, ignore_index=True)\n",
    "            insp_accel_y.columns = [str(col) + '_accel_y_ins' for col in insp_accel_y.columns]\n",
    "            exp_accel_y = pd.concat(features_pat_accel_y_exp, ignore_index=True)\n",
    "            exp_accel_y.columns = [str(col) + '_accel_y_exp' for col in exp_accel_y.columns]\n",
    "            all_breath_accel_y = pd.concat(features_pat_accel_y, ignore_index=True)\n",
    "            all_breath_accel_y.columns = [str(col) + '_accel_y' for col in all_breath_accel_y.columns]\n",
    "            \n",
    "            insp_accel_z = pd.concat(features_pat_accel_z_ins, ignore_index=True)\n",
    "            insp_accel_z.columns = [str(col) + '_accel_z_ins' for col in insp_accel_z.columns]\n",
    "            exp_accel_z = pd.concat(features_pat_accel_z_exp, ignore_index=True)\n",
    "            exp_accel_z.columns = [str(col) + '_accel_z_exp' for col in exp_accel_z.columns]\n",
    "            all_breath_accel_z = pd.concat(features_pat_accel_z, ignore_index=True)\n",
    "            all_breath_accel_z.columns = [str(col) + '_accel_z' for col in all_breath_accel_z.columns]\n",
    "            \n",
    "            features_all.append(pd.concat([insp, exp, all_breath, \n",
    "                                           insp_accel_x, exp_accel_x, all_breath_accel_x,\n",
    "                                           insp_accel_y, exp_accel_y, all_breath_accel_y,\n",
    "                                           insp_accel_z, exp_accel_z, all_breath_accel_z,\n",
    "                                          ], axis=1))\n",
    "    return features_all, Y , bs_all, can_all, accel_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, Y, bs, can, accel = load_data_from_csv_in_dir(\"./Final/\", plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = 0\n",
    "obs_count, norm_count, count = 0, 0, 0\n",
    "for i in range(len(accel)):\n",
    "    obs_count += len(np.where(np.array(Y[i])==1)[0])\n",
    "    norm_count += len(np.where(np.array(Y[i])==0)[0])\n",
    "    count += len(accel[i])\n",
    "    for j in accel[i]:\n",
    "        lengths += len(j)\n",
    "print(\"The duration of recording is: \" + str(floor(lengths/32/60/60)) + \"h \" + str(floor(lengths/32/60%60)) + \"min\")\n",
    "print(\"Total number of breaths:\" + str(count))\n",
    "print(\"Total number of normal breaths: \" + str(norm_count))\n",
    "print(\"The percentage of normal breaths: \" + str(round((norm_count/count)*100,2)))\n",
    "print(\"Total number of obstructed breaths: \" + str(obs_count))\n",
    "print(\"The percentage of obstructed breaths: \" + str(round((obs_count/count)*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = pd.DataFrame()\n",
    "for j in np.arange(len(X)):\n",
    "    for i in np.arange(X[j].shape[0]):\n",
    "        if i > 2:\n",
    "            ratios = ratios.append(X[j].iloc[i]/X[j].iloc[i-1], ignore_index = True)\n",
    "\n",
    "ratios_2prev = pd.DataFrame()\n",
    "for j in np.arange(len(X)):\n",
    "    for i in np.arange(X[j].shape[0]):\n",
    "        if i > 2:\n",
    "            ratios_2prev = ratios_2prev.append(X[j].iloc[i]/X[j].iloc[i-2], ignore_index = True)\n",
    "\n",
    "#NOT USED\n",
    "ratios_3prev = pd.DataFrame()\n",
    "for j in np.arange(len(X)):\n",
    "    for i in np.arange(X[j].shape[0]):\n",
    "        if i > 2:\n",
    "            ratios_3prev = ratios_3prev.append(X[j].iloc[i]/X[j].iloc[i-3], ignore_index = True)\n",
    "\n",
    "\n",
    "selected = [\n",
    "# '0.1quant_accel_x_ins', #lower\n",
    "'0.1quant_accel_z_ins', #lower\n",
    "'0.25quant_accel_x_ins', #lower\n",
    "'0.25quant_accel_z_ins', #lower\n",
    "'0.75quant_accel_z_ins', #lower\n",
    "# '0.9quant_accel_z_ins', #lower\n",
    "# 'mean_accel_x_ins', #lower\n",
    "'mean_accel_z_ins', #lower\n",
    "# 'median_accel_x_ins', #lower\n",
    "'median_accel_z_ins', #lower\n",
    "# 'min_accel_x_ins', #lower\n",
    "'min_accel_z_ins'] #lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_set = ratios\n",
    "Y_set, cannula, ac = [], [], []\n",
    "for i in np.arange(len(Y)):\n",
    "    for j in np.arange(len(Y[i])):\n",
    "        if j >= 3:\n",
    "            Y_set.append(Y[i][j])\n",
    "\n",
    "for i in np.arange(len(can)):\n",
    "    for j in np.arange(len(can[i])):\n",
    "        if j >= 3:\n",
    "            cannula.append(can[i][j])\n",
    "\n",
    "for i in np.arange(len(accel)):\n",
    "    for j in np.arange(len(accel[i])):\n",
    "        if j >= 3:\n",
    "            ac.append(accel[i][j])\n",
    "            \n",
    "cut = 0.2\n",
    "cut_low = round((cut-0.2) * X_set.shape[0])\n",
    "cut_high = round(cut * X_set.shape[0])\n",
    "X_train, y_train, X_valid, y_valid = X_set.iloc[0:cut_low, :].append(X_set.iloc[cut_high:, :]), Y_set[0:cut_low] + Y_set[cut_high:], X_set.iloc[cut_low:cut_high, :], Y_set[cut_low:cut_high]\n",
    "can_train, can_valid = cannula[0:cut_low] + cannula[cut_high:], cannula[cut_low:cut_high]\n",
    "accel_train, accel_valid = ac[0:cut_low] + ac[cut_high:], ac[cut_low:cut_high]\n",
    "X_train, X_valid = X_train.reset_index(drop=True), X_valid.reset_index(drop=True)\n",
    "\n",
    "X_set_2prev = ratios_2prev\n",
    "X_train_2prev, X_valid_2prev = X_set_2prev.iloc[0:cut_low, :].append(X_set_2prev.iloc[cut_high:, :]), X_set_2prev.iloc[cut_low:cut_high, :]\n",
    "X_set_3prev = ratios_3prev\n",
    "X_train_3prev, X_valid_3prev = X_set_3prev.iloc[0:cut_low, :].append(X_set_2prev.iloc[cut_high:, :]), X_set_2prev.iloc[cut_low:cut_high, :]\n",
    "X_train_2prev, X_train_3prev, X_valid_2prev, X_valid_3prev = X_train_2prev.reset_index(drop=True), X_train_3prev.reset_index(drop=True), X_valid_2prev.reset_index(drop=True), X_valid_3prev.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print (ratios_2prev.shape)\n",
    "print (ratios.shape)\n",
    "print(\"Size of the training set: \" + str(len(X_train)))\n",
    "print(\"Size of the validation set: \" + str(len(X_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Baseline</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_train = np.median(y_train)\n",
    "median_valid = np.median(y_valid)\n",
    "check_train = [median_train] * len(y_train)\n",
    "check_valid = [median_valid] * len(y_valid)\n",
    "correct_train = len(np.where(np.array(check_train) == np.array(y_train))[0])\n",
    "correct_valid = len(np.where(np.array(check_valid) == np.array(y_valid))[0])\n",
    "print(\"Training baseline accuracy: \" + str(correct_train/len(y_train)*100))\n",
    "print(str(correct_train) + \" out of \" + str(len(y_train)))\n",
    "print(\"Validation baseline accuracy: \" + str(correct_valid/len(y_valid)*100))\n",
    "print(str(correct_valid) + \" out of \" + str(len(y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Finding all cyclic obstructions throughout the whole dataset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 0\n",
    "j = 0\n",
    "on = 0\n",
    "prev_index = 0\n",
    "period_low, period_high = 3, 4\n",
    "cyclic_j = []\n",
    "for i in np.asarray(X_set.index):\n",
    "    if (Y_set[j] == 1):\n",
    "        cl = Y_set[j]\n",
    "        start = 1\n",
    "        while (cl == 1 and j-start >= 0):\n",
    "            cl = Y_set[j-start]\n",
    "            start += 1\n",
    "        start = j - start + 2\n",
    "        if (j - start >= period_low):\n",
    "            on = 1\n",
    "        else:\n",
    "            on = 0\n",
    "    else:\n",
    "        if (on == 1):\n",
    "            cl = Y_set[j]\n",
    "            end = 1\n",
    "            while cl == 0 and len(Y_set) > j+end:\n",
    "                cl = Y_set[j+end]\n",
    "                end += 1\n",
    "            end = j + end - 1\n",
    "            if (end -j > period_high):\n",
    "                end = j+period_high\n",
    "            if (j - start > period_high):\n",
    "                start = j-period_high\n",
    "            if((cannula[j].max()-cannula[j].min())/(cannula[j-1].max()-cannula[j-1].min()) > 1.5 and \n",
    "                (cannula[j].max()-cannula[j].min())/(cannula[j-2].max()-cannula[j-2].min()) > 1.5 and\n",
    "                (cannula[j].max()-cannula[j].min())/(cannula[j-3].max()-cannula[j-3].min()) > 1.5 and\n",
    "                period_low <= end -j and period_low <= j-start):\n",
    "                    cyclic_j = cyclic_j + list(range(start, end))\n",
    "#                     print(\"Found an interval: \" + \" \" + str(start) + \" \" + str(end) + \" \" +str(Y_set[start:end]))\n",
    "            on = 0\n",
    "        \n",
    "    j += 1\n",
    "print (\"Cyclic obstructions:\")\n",
    "print (\"Number of cyclic periods: \" + str(len(cyclic_j)))\n",
    "print (\"Percentage of cyclic periods: \" + str(len(cyclic_j)/X[0].shape[0]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Plotting accelerometer and cannula values</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(8390, figsize=(9, 3))\n",
    "plt.subplot(1,2,1)\n",
    "length = 0\n",
    "j = 0\n",
    "for i in range(len(Y_set)):\n",
    "        if (Y_set[i] == 0):\n",
    "            plt.plot(np.arange(len(ac[i]))+length, ac[i], '-g')\n",
    "        if (Y_set[i] == 1):\n",
    "            plt.plot(np.arange(len(ac[i]))+length, ac[i], '-r')\n",
    "        length += ac[i].shape[0] + 20\n",
    "        \n",
    "plt.subplot(1,2,2)\n",
    "length = 0\n",
    "j = 0\n",
    "for i in range(len(Y_set)):\n",
    "        if (Y_set[i] == 0):\n",
    "            plt.plot(np.arange(len(cannula[i]))+length, cannula[i], '-g')\n",
    "        if (Y_set[i] == 1):\n",
    "            plt.plot(np.arange(len(cannula[i]))+length, cannula[i], '-r')\n",
    "        length += cannula[i].shape[0] + 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Ratios plots</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(83736, figsize=(12, 95))\n",
    "norm_index, obstr_index = [], []\n",
    "p, counter = 0, 0\n",
    "for j, c in enumerate(Y_set):\n",
    "    if (j > 0 and c != p and counter >= 3):\n",
    "        if(c == 0):\n",
    "            norm_index.append(j)\n",
    "        else:\n",
    "            obstr_index.append(j)\n",
    "    if (p == c and j > 0):\n",
    "        counter += 1\n",
    "    else:\n",
    "        counter = 0\n",
    "    p = c;\n",
    "    \n",
    "i = 1\n",
    "for col in ratios:\n",
    "    if col not in [\"lengthRatio_accel_x_ins\", \"lengthRatio_accel_y_ins\", \"lengthRatio_accel_z_ins\"]:\n",
    "        plt.subplot(44, 5, i)\n",
    "        plt.scatter(np.ones(len(norm_index)), ratios.loc[norm_index, col].values, c='g', alpha=0.2)\n",
    "        plt.scatter(np.ones(len(obstr_index))+0.2, ratios.loc[obstr_index, col].values, c='r', alpha=0.2)\n",
    "        plt.title(col)\n",
    "        plt.tight_layout()\n",
    "        i += 1\n",
    "# plt.savefig(\"both.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Distribution plots</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "selected = ['0.1quant_accel_z_ins','0.25quant_accel_z_ins', '0.75quant_accel_z_ins',\n",
    "            'mean_accel_z_ins', 'median_accel_z_ins', '0.1quant_accel_y',\n",
    "            '0.9quant_accel_y_exp', 'mean_accel_y', 'min_accel_y', 'min_accel_z_ins',\n",
    "            '0.25quant_accel_y', '0.75quant_accel_y',  '0.25quant_accel_x_ins', 'mean_accel_x_ins', 'median_accel_x_ins']\n",
    "f, axes = plt.subplots(3, 5, figsize=(15, 10))\n",
    "count1, count2 = 0, 0\n",
    "for i in selected:\n",
    "    x = ratios[i]\n",
    "    x = round(x, 2)\n",
    "    sns.distplot(ax = axes[count1,count2], a=x)\n",
    "    axes[count1,count2].set_xlim(0.94,1.06)\n",
    "#     plt.xlim(0, 2)\n",
    "    if(count2==4):\n",
    "        count2 = 0\n",
    "        count1 +=1\n",
    "    else: count2+=1\n",
    "    plt.tight_layout()\n",
    "plt.savefig(\"distplots.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Cyclic periods for the training set</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 0\n",
    "j = 0\n",
    "on = 0\n",
    "prev_index = 0\n",
    "period_low, period_high = 3, 4\n",
    "cyclic_j = []\n",
    "for i in np.asarray(X_train.index):\n",
    "    if (y_train[j] == 1):\n",
    "        cl = y_train[j]\n",
    "        start = 1\n",
    "        while (cl == 1 and j-start >= 0):\n",
    "            cl = y_train[j-start]\n",
    "            start += 1\n",
    "        start = j - start + 2\n",
    "        if (j - start >= period_low):\n",
    "            on = 1\n",
    "        else:\n",
    "            on = 0\n",
    "    else:\n",
    "        if (on == 1):\n",
    "            cl = y_train[j]\n",
    "            end = 1\n",
    "            while cl == 0 and len(y_train) > j+end:\n",
    "                cl = y_train[j+end]\n",
    "                end += 1\n",
    "            end = j + end - 1\n",
    "            if (end -j > period_high):\n",
    "                end = j+period_high\n",
    "            if (j - start > period_high):\n",
    "                start = j-period_high\n",
    "            if((can_train[j].max()-can_train[j].min())/(can_train[j-1].max()-can_train[j-1].min()) > 1.5 and \n",
    "                (can_train[j].max()-can_train[j].min())/(can_train[j-2].max()-can_train[j-2].min()) > 1.5 and\n",
    "                (can_train[j].max()-can_train[j].min())/(can_train[j-3].max()-can_train[j-3].min()) > 1.5 and\n",
    "                period_low <= end -j and period_low <= j-start):\n",
    "                    cyclic_j = cyclic_j + list(range(start, end))\n",
    "#                     print(\"Found an interval: \" + \" \" + str(start) + \" \" + str(end) + \" \" +str(y_train[start:end]))\n",
    "            on = 0\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Training the ratios model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_predictions = []\n",
    "thresholds = {}\n",
    "over = []\n",
    "for name in selected:\n",
    "    pred_max = []\n",
    "    pred = 1\n",
    "    max_best, min_best, best_correct, best_wrong = 0, 0, 0, X_train.shape[0]\n",
    "    max_set = np.linspace(1.0, X_train[name].quantile(0.95), num = 100)\n",
    "    min_set = np.linspace(X_train[name].quantile(0.05), 1.0, num = 100)\n",
    "    for max_tre in max_set:\n",
    "        for min_tre in min_set:\n",
    "            correct, wrong = 0, 0\n",
    "            predictions = []\n",
    "            for i, ratio in enumerate(X_train[name]):\n",
    "                    if (ratio > max_tre):\n",
    "                        if name in low_obs:   \n",
    "                            pred = 0\n",
    "                        else: pred = 1\n",
    "                    elif(ratio < min_tre): \n",
    "                        if name in low_obs: \n",
    "                            pred = 1\n",
    "                        else: pred = 0\n",
    "                    if (len(predictions) > 2):\n",
    "#                         if(predictions[-2] == pred and predictions[-1] == pred and pred == 1): #Slowly decreasing obstruction range -> normal\n",
    "#                             if(X_train_2prev[name].iloc[i] < min_tre and name not in low_obs):\n",
    "#                                 pred = 0\n",
    "#                             elif(X_train_2prev[name].iloc[i] > max_tre and name in low_obs):\n",
    "#                                 pred = 0\n",
    "                        if(predictions[-2] == pred and predictions[-1] == pred and pred == 0): #Slowly increasing -> obstruction\n",
    "                            if(X_train_2prev[name].iloc[i] > max_tre and name not in low_obs):\n",
    "                                pred = 1\n",
    "                            elif( X_train_2prev[name].iloc[i] < min_tre and name in low_obs):\n",
    "                                pred = 1\n",
    "                        elif(predictions[-2] != pred and predictions[-1] != pred and pred == 0): #One accidental\n",
    "                            if( X_train_2prev[name].iloc[i] > min_tre and name not in low_obs):\n",
    "                                pred = 1\n",
    "                            elif(X_train_2prev[name].iloc[i] < max_tre and name in low_obs):\n",
    "                                pred = 1\n",
    "                        elif(predictions[-2] != pred and predictions[-1] != pred and pred == 1): #One accidental smaller before\n",
    "                            if(X_train_2prev[name].iloc[i] < max_tre and name not in low_obs):\n",
    "                                pred = 0\n",
    "                            elif(X_train_2prev[name].iloc[i] > min_tre and name in low_obs):\n",
    "                                pred = 0\n",
    "                            \n",
    "                        \n",
    "                    if(y_train[i] == pred):\n",
    "                        correct += 1\n",
    "                    else:\n",
    "                        wrong += 1\n",
    "                        if (wrong > best_wrong):\n",
    "                            break\n",
    "                    predictions.append(pred)\n",
    "            if (correct > best_correct):\n",
    "                best_wrong = wrong\n",
    "                best_correct = correct\n",
    "                min_best = min_tre\n",
    "                max_best = max_tre\n",
    "                pred_max = predictions\n",
    "                thresholds[name + \"_min\"] = min_best\n",
    "                thresholds[name + \"_max\"] = max_best\n",
    "    printmd(\"**\" + name + \"**\")\n",
    "    print (\"Quantile 0.95: \" + str(X_train[name].quantile(0.95)))\n",
    "    print (\"Quantile 0.05: \" + str(X_train[name].quantile(0.05)))\n",
    "    print (str(best_correct) + \" out of \" + str(X_train.shape[0]))\n",
    "    print (\"Accuracy: \" + str(round(best_correct/X_train.shape[0] * 100, 2)) +\"%\")\n",
    "    over.append(name)\n",
    "    print(min_best)\n",
    "    print(max_best)\n",
    "    final_predictions.append(pred_max)\n",
    "print (thresholds)  \n",
    "print(over)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Predictions for the training set</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medians = []\n",
    "correct = 0\n",
    "correct_cyclic = 0\n",
    "indet = 0\n",
    "for i, pred in enumerate(zip(*final_predictions)):\n",
    "    med_pred = median(pred)\n",
    "    if (med_pred == y_train[i]):\n",
    "        correct += 1\n",
    "        if i in cyclic_j:\n",
    "            correct_cyclic += 1\n",
    "    if (med_pred == 0.5):\n",
    "        indet += 1\n",
    "    medians.append(med_pred)\n",
    "plt.figure(545, figsize=(10, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "length = 0\n",
    "j = 0\n",
    "for i in np.asarray(X_train.index):\n",
    "    if (j in cyclic_j):\n",
    "        if (medians[j] == 0):\n",
    "            plt.plot(np.arange(len(can_train[j]))+length, can_train[j], '-g')\n",
    "        if (medians[j] == 1):\n",
    "            plt.plot(np.arange(len(can_train[j]))+length, can_train[j], '-r')\n",
    "        if (y_train[j] == 0):\n",
    "            plt.plot(np.arange(len(can_train[j]))+length, can_train[j]-0.02, '-g')\n",
    "        else:\n",
    "            plt.plot(np.arange(len(can_train[j]))+length, can_train[j]-0.02, '-r')\n",
    "    length += can_train[j].shape[0] + 20\n",
    "    j += 1\n",
    "plt.title(\"Cannula\")\n",
    "plt.subplot(1, 2, 2)\n",
    "length = 0\n",
    "j = 0\n",
    "for i in np.asarray(X_train.index):\n",
    "    if (j in cyclic_j):\n",
    "        if (medians[j] == 0):\n",
    "            plt.plot(np.arange(len(accel_train[i]))+length, accel_train[i]['accel_y'], '-g')\n",
    "        if (medians[j] == 1):\n",
    "            plt.plot(np.arange(len(accel_train[i]))+length, accel_train[i]['accel_y'], '-r')\n",
    "        if (y_train[j] == 0):\n",
    "            plt.plot(np.arange(len(accel_train[i]))+length, accel_train[i]['accel_y']-0.4, '-g')\n",
    "        else:\n",
    "            plt.plot(np.arange(len(accel_train[i]))+length, accel_train[i]['accel_y']-0.4, '-r')\n",
    "    length += can_train[i].shape[0] + 20\n",
    "    j += 1\n",
    "plt.title(\"Breathing signal\")\n",
    "print (\"Correct: \" + str(correct))\n",
    "print (\"Indeterminate: \" + str(indet))\n",
    "print (\"Total: \" + str(len(y_train)))\n",
    "print (\"Accuracy: \" + str(round(correct/len(y_train) * 100, 2)))\n",
    "print (\"Cyclic Accuracy: \" + str(round(correct_cyclic/len(cyclic_j) * 100, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Cyclic periods for the validation set</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Cyclic obstructions:\")\n",
    "print(y_valid)\n",
    "length = 0\n",
    "j = 0\n",
    "on = 0\n",
    "prev_index = 0\n",
    "period_low, period_high = 3, 5\n",
    "cyclic_j = []\n",
    "for i in np.asarray(X_valid.index):\n",
    "    if (y_valid[j] == 1):\n",
    "        cl = y_valid[j]\n",
    "        start = 1\n",
    "        while (cl == 1 and j-start >= 0):\n",
    "            cl = y_valid[j-start]\n",
    "            start += 1\n",
    "        start = j - start + 2\n",
    "        if (j - start >= period_low):\n",
    "            on = 1\n",
    "        else:\n",
    "            on = 0\n",
    "    else:\n",
    "        if (on == 1):\n",
    "            cl = y_valid[j]\n",
    "            end = 1\n",
    "            while cl == 0 and len(y_valid) > j+end:\n",
    "                cl = y_valid[j+end]\n",
    "                end += 1\n",
    "            end = j + end - 1\n",
    "            if (end -j > period_high):\n",
    "                end = j+period_high\n",
    "            if (j - start > period_high):\n",
    "                start = j-period_high\n",
    "            if((can_valid[j].max()-can_valid[j].min())/(can_valid[j-1].max()-can_valid[j-1].min()) > 1.5 and\n",
    "                (can_valid[j].max()-can_valid[j].min())/(can_valid[j-2].max()-can_valid[j-2].min()) > 1.5 and\n",
    "                (can_valid[j].max()-can_valid[j].min())/(can_valid[j-3].max()-can_valid[j-3].min()) > 1.5 and\n",
    "                period_low <= end -j and period_low <= j-start):\n",
    "                cyclic_j = cyclic_j + list(range(start, end))\n",
    "#                 print(\"Found an interval: \" + \" \" + str(start) + \" \" + str(end) + \" \" +str(y_valid[start:end]))\n",
    "            on = 0\n",
    "        \n",
    "            \n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Predictions for the validation set</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions_valid = []\n",
    "for name in selected:\n",
    "    pred = 1\n",
    "    predictions = []\n",
    "    max_tre = thresholds[name+\"_max\"]\n",
    "    min_tre = thresholds[name+\"_min\"]\n",
    "    for i, ratio in enumerate(X_valid[name]):\n",
    "        if (ratio > max_tre):\n",
    "            if name not in low_obs:   \n",
    "                pred = 1\n",
    "            else: pred = 0\n",
    "        elif(ratio < min_tre): \n",
    "            if name not in low_obs: \n",
    "                pred = 0\n",
    "            else: pred = 1\n",
    "        if (len(predictions) > 3):\n",
    "#             if(predictions[-2] == pred and predictions[-1] == pred and pred == 1): #Slowly decreasing obstruction range -> normal\n",
    "#                 if(X_valid_2prev[name].iloc[i] < min_tre and name not in low_obs):\n",
    "#                     pred = 0\n",
    "#                 elif(X_valid_2prev[name].iloc[i] > max_tre and name in low_obs):\n",
    "#                     pred = 0\n",
    "            if(predictions[-2] == pred and predictions[-1] == pred and pred == 0): #Slowly increasing -> obstruction\n",
    "                if(X_valid_2prev[name].iloc[i] > max_tre and name not in low_obs):\n",
    "                    pred = 1\n",
    "                if(X_valid_2prev[name].iloc[i] < min_tre and name in low_obs):\n",
    "                    pred = 1\n",
    "            elif(predictions[-2] != pred and predictions[-1] != pred and pred == 0): #One accidental larger before\n",
    "                if(X_valid_2prev[name].iloc[i] > min_tre and name not in low_obs):\n",
    "                    pred = 1\n",
    "                elif(X_valid_2prev[name].iloc[i] < max_tre and name in low_obs):\n",
    "                    pred = 1\n",
    "            elif(predictions[-2] != pred and predictions[-1] != pred and pred == 1): #One accidental smaller before\n",
    "                if(X_valid_2prev[name].iloc[i] < max_tre and name not in low_obs):\n",
    "                    pred = 0\n",
    "                elif(X_valid_2prev[name].iloc[i] > min_tre and name in low_obs):\n",
    "                    pred = 0\n",
    "        predictions.append(pred)\n",
    "    final_predictions_valid.append(predictions)\n",
    "\n",
    "medians = []\n",
    "correct = 0\n",
    "correct_cyclic = 0\n",
    "indet = 0\n",
    "y_v = y_valid\n",
    "for i, pred in enumerate(zip(*final_predictions_valid)):\n",
    "        med_pred = median(pred)\n",
    "        if (med_pred == y_valid[i]):\n",
    "            if(i in cyclic_j):\n",
    "                correct_cyclic += 1\n",
    "            correct += 1\n",
    "        if (med_pred == 0.5):\n",
    "            indet += 1\n",
    "        medians.append(med_pred)\n",
    "plt.figure(5245, figsize=(10, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "length = 0\n",
    "j = 0\n",
    "for i in np.asarray(X_valid.index):\n",
    "#         if(j in cyclic_j):\n",
    "            if (medians[j] == 0):\n",
    "        #         plt.plot(np.arange(len(accel_valid[j]))+length, accel_valid[j]-0.2, '-g')\n",
    "                plt.plot(np.arange(len(can_valid[j]))+length, can_valid[j], '-g')\n",
    "            if (medians[j] == 1):\n",
    "        #         plt.plot(np.arange(len(accel_valid[j]))+length, accel_valid[j]-0.2, '-r')\n",
    "                plt.plot(np.arange(len(can_valid[j]))+length, can_valid[j], '-r')\n",
    "            if (y_v[j] == 0):\n",
    "                plt.plot(np.arange(len(can_valid[j]))+length, can_valid[j]-0.04, '-g')\n",
    "            else:\n",
    "                plt.plot(np.arange(len(can_valid[j]))+length, can_valid[j]-0.04, '-r')\n",
    "            length += can_valid[j].shape[0] + 20\n",
    "            j += 1\n",
    "plt.title(\"Cannula\")\n",
    "plt.subplot(1, 2, 2)\n",
    "length = 0\n",
    "j = 0\n",
    "prev_index = 0\n",
    "for i in np.asarray(X_valid.index):\n",
    "    if(j in cyclic_j):\n",
    "        if (medians[j] == 0):\n",
    "    #         plt.plot(np.arange(len(accel_valid[j]))+length, accel_valid[j]-0.2, '-g')\n",
    "            plt.plot(np.arange(len(accel_valid[j]))+length, accel_valid[j], '-g')\n",
    "        if (medians[j] == 1):\n",
    "    #         plt.plot(np.arange(len(accel_valid[j]))+length, accel_valid[j]-0.2, '-r')\n",
    "            plt.plot(np.arange(len(accel_valid[j]))+length, accel_valid[j], '-r')\n",
    "        if (y_v[j] == 0):\n",
    "            plt.plot(np.arange(len(accel_valid[j]))+length, accel_valid[j]-0.1, '-g')\n",
    "        else:\n",
    "            plt.plot(np.arange(len(accel_valid[j]))+length, accel_valid[j]-0.1, '-r')\n",
    "    length += accel_valid[j].shape[0] + 20\n",
    "    j += 1\n",
    "plt.title(\"Breathing signal\")\n",
    "# plt.xlim([23700, 25000])\n",
    "\n",
    "print(cyclic_j)\n",
    "    \n",
    "print (\"Correct: \" + str(correct))\n",
    "print (\"Indeterminate: \" + str(indet))\n",
    "print (\"Total: \" + str(len(y_valid)))\n",
    "print (\"Accuracy: \" + str(round(correct/len(y_valid) * 100, 2)))\n",
    "print (\"Accuracy of cyclic: \" + str(round(correct_cyclic/len(cyclic_j) * 100, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Baseline k-folds</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_acc, val_acc = [], []\n",
    "for cut in [0.2, 0.4, 0.6, 0.8, 1.0]:\n",
    "    cut_low = round((cut-0.2) * X_set.shape[0])\n",
    "    cut_high = round(cut * X_set.shape[0])\n",
    "    y_train, y_valid = Y_set[0:cut_low] + Y_set[cut_high:], Y_set[cut_low:cut_high]\n",
    "    median_train = np.median(y_train)\n",
    "    median_valid = np.median(y_valid)\n",
    "    check_train = [median_train] * len(y_train)\n",
    "    check_valid = [median_valid] * len(y_valid)\n",
    "    correct_train = len(np.where(np.array(check_train) == np.array(y_train))[0])\n",
    "    correct_valid = len(np.where(np.array(check_valid) == np.array(y_valid))[0])\n",
    "    tr_acc += [correct_train/len(y_train)*100]\n",
    "    val_acc += [correct_valid/len(y_valid)*100]\n",
    "print(\"K-fold baseline training accuracy: \" + str(np.mean(tr_acc)))\n",
    "print(\"K-fold baseline validation accuracy: \" + str(np.mean(val_acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>K-folds between subsets of a set or just a regular k-folds</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "selected = ['0.1quant_accel_x_ins', #lower\n",
    "# '0.1quant_accel_y', #lower\n",
    "'0.1quant_accel_z_ins', #lower\n",
    "'0.25quant_accel_x_ins', #lower\n",
    "# '0.25quant_accel_y', #lower\n",
    "'0.25quant_accel_z_ins', #lower\n",
    "# '0.75quant_accel_y', #lower\n",
    "'0.75quant_accel_z_ins', #lower\n",
    "# '0.9quant_accel_y_exp', #lower\n",
    "'0.9quant_accel_z_ins', #lower\n",
    "# 'max_accel_y', #lower\n",
    "# 'mean_accel_y', #lower\n",
    "'mean_accel_x_ins', #lower\n",
    "'mean_accel_z_ins', #lower\n",
    "'median_accel_x_ins', #lower\n",
    "# 'median_accel_y', #lower\n",
    "'median_accel_z_ins', #lower\n",
    "# 'min-mean_accel_z', #higher\n",
    "'min_accel_x_ins', #lower\n",
    "# 'min_accel_y', #lower\n",
    "'min_accel_z_ins'] #lower\n",
    "# 'std_accel_x_ins'] #higher]\n",
    "\n",
    "selected = ['0.1quant_accel_x_ins', #lower\n",
    "'0.1quant_accel_y', #lower\n",
    "'0.1quant_accel_z_ins', #lower\n",
    "'0.25quant_accel_x_ins', #lower\n",
    "# '0.25quant_accel_y', #lower\n",
    "'0.25quant_accel_z_ins', #lower\n",
    "# '0.75quant_accel_y', #lower\n",
    "'0.75quant_accel_z_ins', #lower\n",
    "'0.9quant_accel_y_exp', #lower\n",
    "'0.9quant_accel_z_ins', #lower\n",
    "# 'max_accel_y', #lower\n",
    "'mean_accel_y', #lower\n",
    "'mean_accel_x_ins', #lower\n",
    "'mean_accel_z_ins', #lower\n",
    "# 'median_accel_x_ins', #lower\n",
    "# 'median_accel_y', #lower\n",
    "'median_accel_z_ins', #lower\n",
    "# 'min-mean_accel_z', #higher\n",
    "# 'min_accel_x_ins', #lower\n",
    "# 'min_accel_y', #lower\n",
    "'min_accel_z_ins'] #lower\n",
    "# 'std_accel_x_ins'] #higher]\n",
    "\n",
    "selected = ['0.1quant_accel_z_ins','0.25quant_accel_z_ins', '0.75quant_accel_z_ins',\n",
    "            'mean_accel_z_ins', 'median_accel_z_ins', '0.1quant_accel_y',\n",
    "            '0.9quant_accel_y_exp', 'mean_accel_y', 'min_accel_y', 'min_accel_z_ins',\n",
    "            '0.25quant_accel_y', '0.75quant_accel_y',  '0.25quant_accel_x_ins', 'mean_accel_x_ins', 'median_accel_x_ins']\n",
    "\n",
    "selected = ['0.1quant_accel_z_ins', '0.25quant_accel_z_ins', '0.75quant_accel_z_ins', 'mean_accel_z_ins', 'median_accel_z_ins', '0.1quant_accel_y', '0.9quant_accel_y_exp', 'mean_accel_y', 'min_accel_y', 'min_accel_z_ins', '0.25quant_accel_y', '0.75quant_accel_y', '0.25quant_accel_x_ins', 'mean_accel_x_ins', 'median_accel_x_ins']\n",
    "\n",
    "subs = [selected]\n",
    "best_ft, best_val, best_tr, best_val_cyc, best_tr_cyc = [], 0, 0, 0, 0\n",
    "period_low, period_high = 3, 4\n",
    "for selected in subs:\n",
    "    tr_acc, tr_acc_cyc = [], []\n",
    "    val_acc, val_acc_cyc = [], []\n",
    "    printmd(\"**K-fold started**\")\n",
    "    print(\"Features: \", end=\" \")\n",
    "    print(selected)\n",
    "    for cut in [0.2, 0.4, 0.6, 0.8, 1.0]:\n",
    "        cut_low = round((cut-0.2) * X_set.shape[0])\n",
    "        cut_high = round(cut * X_set.shape[0])\n",
    "        X_train, y_train, X_valid, y_valid = X_set.iloc[0:cut_low, :].append(X_set.iloc[cut_high:, :]), Y_set[0:cut_low] + Y_set[cut_high:], X_set.iloc[cut_low:cut_high, :], Y_set[cut_low:cut_high]\n",
    "        can_train, can_valid = cannula[0:cut_low] + cannula[cut_high:], cannula[cut_low:cut_high]\n",
    "        X_train, X_valid = X_train.reset_index(drop=True), X_valid.reset_index(drop=True)\n",
    "\n",
    "        X_set_2prev = ratios_2prev\n",
    "        X_train_2prev, X_valid_2prev = X_set_2prev.iloc[0:cut_low, :].append(X_set_2prev.iloc[cut_high:, :]), X_set_2prev.iloc[cut_low:cut_high, :]\n",
    "        X_set_3prev = ratios_3prev\n",
    "        X_train_3prev, X_valid_3prev = X_set_3prev.iloc[0:cut_low, :].append(X_set_2prev.iloc[cut_high:, :]), X_set_2prev.iloc[cut_low:cut_high, :]\n",
    "        X_train_2prev, X_train_3prev, X_valid_2prev, X_valid_3prev = X_train_2prev.reset_index(drop=True), X_train_3prev.reset_index(drop=True), X_valid_2prev.reset_index(drop=True), X_valid_3prev.reset_index(drop=True)\n",
    "        final_predictions = []\n",
    "        thresholds = {}\n",
    "        over = []\n",
    "        #New only cyclic\n",
    "        length = 0\n",
    "        j = 0\n",
    "        on = 0\n",
    "        prev_index = 0\n",
    "        cyclic_j = []\n",
    "        for i in np.asarray(X_train.index):\n",
    "            if (y_train[j] == 1):\n",
    "                cl = y_train[j]\n",
    "                start = 1\n",
    "                while (cl == 1 and j-start >= 0):\n",
    "                    cl = y_train[j-start]\n",
    "                    start += 1\n",
    "                start = j - start + 2\n",
    "                if (j - start >= period_low):\n",
    "                    on = 1\n",
    "                else:\n",
    "                    on = 0\n",
    "            else:\n",
    "                if (on == 1):\n",
    "                    cl = y_train[j]\n",
    "                    end = 1\n",
    "                    while cl == 0 and len(y_train) > j+end:\n",
    "                        cl = y_train[j+end]\n",
    "                        end += 1\n",
    "                    end = j + end - 1\n",
    "                    if (end -j > period_high):\n",
    "                        end = j+period_high\n",
    "                    if (j - start > period_high):\n",
    "                        start = j-period_high\n",
    "                    if((can_train[j].max()-can_train[j].min())/(can_train[j-1].max()-can_train[j-1].min()) > 1.5 and \n",
    "                       (can_train[j].max()-can_train[j].min())/(can_train[j-2].max()-can_train[j-2].min()) > 1.5 and\n",
    "                       (can_train[j].max()-can_train[j].min())/(can_train[j-3].max()-can_train[j-3].min()) > 1.5 and\n",
    "                       period_low <= end -j and period_low <= j-start):\n",
    "                        cyclic_j = cyclic_j + list(range(start, end))\n",
    "                    on = 0\n",
    "            j += 1\n",
    "        for name in selected:\n",
    "            pred_max = []\n",
    "            pred = 1\n",
    "            max_best, min_best, best_correct, best_wrong, best_all_correct = 0, 0, 0, X_train.shape[0], 0\n",
    "            max_set = np.linspace(1.0, X_train[name].quantile(0.95), num = 100)\n",
    "            min_set = np.linspace(X_train[name].quantile(0.05), 1.0, num = 100)\n",
    "\n",
    "            for max_tre in max_set:\n",
    "                for min_tre in min_set:\n",
    "                    correct, wrong, all_correct = 0, 0, 0\n",
    "                    predictions = []\n",
    "                    for i, ratio in enumerate(X_train[name]):\n",
    "                            if (ratio > max_tre):\n",
    "                                if name in low_obs:   \n",
    "                                    pred = 0\n",
    "                                else: pred = 1\n",
    "                            elif(ratio < min_tre): \n",
    "                                if name in low_obs: \n",
    "                                    pred = 1\n",
    "                                else: pred = 0\n",
    "                            if (len(predictions) > 2):\n",
    "#                                 if(predictions[-2] == pred and predictions[-1] == pred and pred == 1): #Slowly decreasing obstruction range -> normal\n",
    "#                                     if(X_train_2prev[name].iloc[i] < min_tre and name not in low_obs):\n",
    "#                                         pred = 0\n",
    "#                                     elif(X_train_2prev[name].iloc[i] > max_tre and name in low_obs):\n",
    "#                                         pred = 0\n",
    "                                if(predictions[-2] == pred and predictions[-1] == pred and pred == 0): #Slowly increasing -> obstruction\n",
    "                                    if(X_train_2prev[name].iloc[i] > max_tre and name not in low_obs):\n",
    "                                        pred = 1\n",
    "                                    elif(X_train_2prev[name].iloc[i] < min_tre and name in low_obs):\n",
    "                                        pred = 1\n",
    "                                elif(predictions[-2] != pred and predictions[-1] != pred and pred == 0): #One accidental\n",
    "                                    if(X_train_2prev[name].iloc[i] > min_tre and name not in low_obs):\n",
    "                                        pred = 1\n",
    "                                    elif(X_train_2prev[name].iloc[i] < max_tre and name in low_obs):\n",
    "                                        pred = 1\n",
    "                                elif(predictions[-2] != pred and predictions[-1] != pred and pred == 1): #One accidental smaller before\n",
    "                                    if(X_train_2prev[name].iloc[i] < max_tre and name not in low_obs):\n",
    "                                        pred = 0\n",
    "                                    elif(X_train_2prev[name].iloc[i] > min_tre and name in low_obs):\n",
    "                                        pred = 0\n",
    "\n",
    "\n",
    "                            if(y_train[i] == pred and i in cyclic_j):\n",
    "                                correct += 1 \n",
    "                            if(y_train[i] == pred):\n",
    "                                all_correct += 1 \n",
    "                            if(y_train[i] != pred and i in cyclic_j):\n",
    "                                wrong += 1\n",
    "                                if (wrong > best_wrong):\n",
    "                                    break\n",
    "                            predictions.append(pred)\n",
    "                    if (correct > best_correct or (correct==best_correct and all_correct > best_all_correct)):\n",
    "                        best_correct = correct\n",
    "                        best_wrong = wrong\n",
    "                        best_all_correct = all_correct\n",
    "                        min_best = min_tre\n",
    "                        max_best = max_tre\n",
    "                        pred_max = predictions\n",
    "                        thresholds[name + \"_min\"] = min_best\n",
    "                        thresholds[name + \"_max\"] = max_best\n",
    "            final_predictions.append(pred_max)\n",
    "        \n",
    "        medians = []\n",
    "        correct = 0\n",
    "        correct_cyclic = 0\n",
    "        indet = 0\n",
    "        for i, pred in enumerate(zip(*final_predictions)):\n",
    "            med_pred = median(pred)\n",
    "            if (med_pred == y_train[i]):\n",
    "                correct += 1\n",
    "                if i in cyclic_j:\n",
    "                    correct_cyclic += 1\n",
    "            if (med_pred == 0.5):\n",
    "                indet += 1\n",
    "            medians.append(med_pred)\n",
    "        tr_acc += [round(correct/len(y_train) * 100, 4)]\n",
    "        tr_acc_cyc += [round(correct_cyclic/len(cyclic_j) * 100, 4)]\n",
    "        final_predictions_valid = []\n",
    "        for name in selected:\n",
    "            pred = 1\n",
    "            predictions = []\n",
    "            max_tre = thresholds[name+\"_max\"]\n",
    "            min_tre = thresholds[name+\"_min\"]\n",
    "            for i, ratio in enumerate(X_valid[name]):\n",
    "                if (ratio > max_tre):\n",
    "                    if name not in low_obs:   \n",
    "                        pred = 1\n",
    "                    else: pred = 0\n",
    "                elif(ratio < min_tre): \n",
    "                    if name not in low_obs: \n",
    "                        pred = 0\n",
    "                    else: pred = 1\n",
    "                if (len(predictions) > 2):\n",
    "#                     if(predictions[-2] == pred and predictions[-1] == pred and pred == 1): #Slowly decreasing obstruction range -> normal\n",
    "#                         if(X_valid_2prev[name].iloc[i] < min_tre and name not in low_obs):\n",
    "#                             pred = 0\n",
    "#                         elif(X_valid_2prev[name].iloc[i] > max_tre and name in low_obs):\n",
    "#                             pred = 0\n",
    "                    if(predictions[-2] == pred and predictions[-1] == pred and pred == 0): #Slowly increasing -> obstruction\n",
    "                        if(X_valid_2prev[name].iloc[i] > max_tre and name not in low_obs):\n",
    "                            pred = 1\n",
    "                        if(X_valid_2prev[name].iloc[i] < min_tre and name in low_obs):\n",
    "                            pred = 1\n",
    "                    elif(predictions[-2] != pred and predictions[-1] != pred and pred == 0): #One accidental larger before\n",
    "                        if(X_valid_2prev[name].iloc[i] > min_tre and name not in low_obs):\n",
    "                            pred = 1\n",
    "                        elif(X_valid_2prev[name].iloc[i] < max_tre and name in low_obs):\n",
    "                            pred = 1\n",
    "                    elif(predictions[-2] != pred and predictions[-1] != pred and pred == 1): #One accidental smaller before\n",
    "                        if(X_valid_2prev[name].iloc[i] < max_tre and name not in low_obs):\n",
    "                            pred = 0\n",
    "                        elif(X_valid_2prev[name].iloc[i] > min_tre and name in low_obs):\n",
    "                            pred = 0\n",
    "                predictions.append(pred)\n",
    "            final_predictions_valid.append(predictions)\n",
    "        length = 0\n",
    "        j = 0\n",
    "        on = 0\n",
    "        prev_index = 0\n",
    "        cyclic_j = []\n",
    "        for i in np.asarray(X_valid.index):\n",
    "            if (y_valid[j] == 1):\n",
    "                cl = y_valid[j]\n",
    "                start = 1\n",
    "                while (cl == 1 and j-start >= 0):\n",
    "                    cl = y_valid[j-start]\n",
    "                    start += 1\n",
    "                start = j - start + 2\n",
    "                if (j - start >= period_low):\n",
    "                    on = 1\n",
    "                else:\n",
    "                    on = 0\n",
    "            else:\n",
    "                if (on == 1):\n",
    "                    cl = y_valid[j]\n",
    "                    end = 1\n",
    "                    while cl == 0 and len(y_valid) > j+end:\n",
    "                        cl = y_valid[j+end]\n",
    "                        end += 1\n",
    "                    end = j + end - 1\n",
    "                    if (end -j > period_high):\n",
    "                        end = j+period_high\n",
    "                    if (j - start > period_high):\n",
    "                        start = j-period_high\n",
    "                    if((can_valid[j].max()-can_valid[j].min())/(can_valid[j-1].max()-can_valid[j-1].min()) > 1.5 and\n",
    "                       (can_valid[j].max()-can_valid[j].min())/(can_valid[j-2].max()-can_valid[j-2].min()) > 1.5 and \n",
    "                       (can_valid[j].max()-can_valid[j].min())/(can_valid[j-3].max()-can_valid[j-3].min()) > 1.5 and\n",
    "                       period_low <= end -j and period_low <= j-start):\n",
    "                        cyclic_j = cyclic_j + list(range(start, end))\n",
    "                    on = 0\n",
    "            j += 1\n",
    "        medians = []\n",
    "        correct = 0\n",
    "        correct_cyclic = 0\n",
    "        indet = 0\n",
    "        for i, pred in enumerate(zip(*final_predictions_valid)):\n",
    "                med_pred = median(pred)\n",
    "                if (med_pred == y_valid[i]):\n",
    "                    if(i in cyclic_j):\n",
    "                        correct_cyclic += 1\n",
    "                    correct += 1\n",
    "                if (med_pred == 0.5):\n",
    "                    indet += 1\n",
    "                medians.append(med_pred)\n",
    "        printmd(\"**VALIDATION**\")\n",
    "        print (\"Correct: \" + str(correct))\n",
    "        print (\"Indeterminate: \" + str(indet))\n",
    "        print (\"Total: \" + str(len(y_valid)))\n",
    "        print (\"Accuracy: \" + str(round(correct/len(y_valid) * 100, 2)))\n",
    "        print (\"Accuracy of cyclic: \" + str(round(correct_cyclic/len(cyclic_j) * 100, 2)))\n",
    "        print(\"Number of cyclic breaths: \" + str(len(cyclic_j)))\n",
    "        val_acc += [round(correct/len(y_valid) * 100, 4)]\n",
    "        val_acc_cyc += [round(correct_cyclic/len(cyclic_j) * 100, 4)]\n",
    "    printmd(\"**K-fold done**\")\n",
    "    print(\"K-fold training accuracy: \" + str(np.mean(tr_acc)))\n",
    "    print(\"K-fold training cyclic accuracy: \" + str(np.mean(tr_acc_cyc)))\n",
    "    print(\"K-fold validation accuracy: \" + str(np.mean(val_acc)))\n",
    "    print(\"K-fold validation cyclic accuracy: \" + str(np.mean(val_acc_cyc)))\n",
    "    if(np.mean(val_acc) > best_val):\n",
    "        best_val = np.mean(val_acc)\n",
    "        best_tr = np.mean(tr_acc)\n",
    "        best_val_cyc = np.mean(val_acc_cyc)\n",
    "        best_tr_cyc = np.mean(tr_acc_cyc)\n",
    "        best_ft = selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain, combinations\n",
    " \n",
    "selected =[\n",
    "'0.25quant_accel_y',\n",
    "'0.75quant_accel_y',\n",
    "'0.9quant',\n",
    "'0.9quant_accel_y',\n",
    "'max-mean',\n",
    "'max_accel_y',\n",
    "'mean_accel_y',\n",
    "'median_accel_y',\n",
    "'range',\n",
    "'std',\n",
    "'std_accel_z']\n",
    "def all_subsets(ss):\n",
    "    return chain(*map(lambda x: combinations(ss, x), range(0, len(ss)+1)))\n",
    "subs = []\n",
    "for subset in all_subsets(selected):\n",
    "    subset = list(subset)\n",
    "    if (len(subset) > 9):\n",
    "        subs.append(subset)\n",
    "print (len(subs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Testing each feature on accuracy</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 0: 'lengthRatio_ins', 'length_ins', 'max-mean', 'max-mean_exp', 'max-mean_ins', 'range', 'range_exp', 'range_ins',  'std', 'std_exp', 'std_ins'\n",
    "# 1: 'mean_cross_exp', mean_cross_ins', 'min-mean', 'min-mean_exp', 'min-mean_ins', 'peaks', 'peaks_exp', 'peaks_ins', \n",
    "# selected = ['lengthRatio_ins', 'length_ins', 'length_exp', 'range', 'range_exp', 'range_ins', 'std', 'std_exp', 'std_ins']\n",
    "selected =[\n",
    "'0.25quant_accel_y',\n",
    "'0.75quant_accel_y',\n",
    "'0.9quant',\n",
    "'0.9quant_accel_y',\n",
    "'max-mean',\n",
    "'max_accel_y',\n",
    "'mean_accel_y',\n",
    "'median_accel_y',\n",
    "'range',\n",
    "'std',\n",
    "'std_accel_z']\n",
    "\n",
    "selected = ['0.1quant_accel_x_ins', #lower\n",
    "'0.1quant_accel_y', #lower\n",
    "'0.1quant_accel_z_ins', #lower\n",
    "'0.25quant_accel_x_ins', #lower\n",
    "'0.25quant_accel_y', #lower\n",
    "'0.25quant_accel_z_ins', #lower\n",
    "'0.75quant_accel_y', #lower\n",
    "'0.75quant_accel_z_ins', #lower\n",
    "'0.9quant_accel_y_exp', #lower\n",
    "'0.9quant_accel_z_ins', #lower\n",
    "'max_accel_y', #lower\n",
    "'mean_accel_y', #lower\n",
    "'mean_accel_x_ins', #lower\n",
    "'mean_accel_z_ins', #lower\n",
    "'median_accel_x_ins', #lower\n",
    "'median_accel_y', #lower\n",
    "'median_accel_z_ins', #lower\n",
    "'min-mean_accel_z', #higher\n",
    "'min_accel_x_ins', #lower\n",
    "'min_accel_y', #lower\n",
    "'min_accel_z_ins', #lower\n",
    "'std_accel_x_ins'] #higher]\n",
    "\n",
    "subs = [selected]\n",
    "best_ft, best_val, best_tr, best_val_cyc, best_tr_cyc = [], 0, 0, 0, 0\n",
    "period_low, period_high = 3, 4\n",
    "feature_acc_all = []\n",
    "for name in selected:\n",
    "    tr_acc, tr_acc_cyc = [], []\n",
    "    val_acc, val_acc_cyc = [], []\n",
    "    \n",
    "    final_predictions = []\n",
    "    thresholds = {}\n",
    "    over = []\n",
    "    feature_acc = []\n",
    "    for cut in [0.2, 0.4, 0.6, 0.8, 1.0]:\n",
    "        pred_max = []\n",
    "        pred = 1\n",
    "        cut_low = round((cut-0.2) * X_set.shape[0])\n",
    "        cut_high = round(cut * X_set.shape[0])\n",
    "        X_train, y_train, X_valid, y_valid = X_set.iloc[0:cut_low, :].append(X_set.iloc[cut_high:, :]), Y_set[0:cut_low] + Y_set[cut_high:], X_set.iloc[cut_low:cut_high, :], Y_set[cut_low:cut_high]\n",
    "        can_train, can_valid = cannula[0:cut_low] + cannula[cut_high:], cannula[cut_low:cut_high]\n",
    "        X_train, X_valid = X_train.reset_index(drop=True), X_valid.reset_index(drop=True)\n",
    "\n",
    "        X_set_2prev = ratios_2prev\n",
    "        X_train_2prev, X_valid_2prev = X_set_2prev.iloc[0:cut_low, :].append(X_set_2prev.iloc[cut_high:, :]), X_set_2prev.iloc[cut_low:cut_high, :]\n",
    "        X_set_3prev = ratios_3prev\n",
    "        X_train_3prev, X_valid_3prev = X_set_3prev.iloc[0:cut_low, :].append(X_set_2prev.iloc[cut_high:, :]), X_set_2prev.iloc[cut_low:cut_high, :]\n",
    "        X_train_2prev, X_train_3prev, X_valid_2prev, X_valid_3prev = X_train_2prev.reset_index(drop=True), X_train_3prev.reset_index(drop=True), X_valid_2prev.reset_index(drop=True), X_valid_3prev.reset_index(drop=True)\n",
    "\n",
    "        max_best, min_best, best_correct, best_wrong = 0, 0, 0, X_train.shape[0]\n",
    "        max_set = np.linspace(1.0, X_train[name].quantile(0.95), num = 100)\n",
    "        min_set = np.linspace(X_train[name].quantile(0.05), 1.0, num = 100)\n",
    "            \n",
    "        for max_tre in max_set:\n",
    "            for min_tre in min_set:\n",
    "                correct, wrong = 0, 0\n",
    "                predictions = []\n",
    "                for i, ratio in enumerate(X_train[name]):\n",
    "                        if (ratio > max_tre):\n",
    "                            if name in low_obs:  \n",
    "                                pred = 0\n",
    "                            else: pred = 1\n",
    "                        elif(ratio < min_tre): \n",
    "                            if name in low_obs: \n",
    "                                pred = 1\n",
    "                            else: pred = 0\n",
    "                        if (len(predictions) > 2):\n",
    "#                                 if(predictions[-2] == pred and predictions[-1] == pred and pred == 1): #Slowly decreasing obstruction range -> normal\n",
    "#                                     if(X_train_2prev[name].iloc[i] < min_tre and name not in low_obs):\n",
    "#                                         pred = 0\n",
    "#                                     elif(X_train_2prev[name].iloc[i] > max_tre and name in low_obs):\n",
    "#                                         pred = 0\n",
    "                            if(predictions[-2] == pred and predictions[-1] == pred and pred == 0): #Slowly increasing -> obstruction\n",
    "                                if(X_train_2prev[name].iloc[i] > max_tre and name not in low_obs):\n",
    "                                    pred = 1\n",
    "                                elif(X_train_2prev[name].iloc[i] < min_tre and name in low_obs):\n",
    "                                    pred = 1\n",
    "                            elif(predictions[-2] != pred and predictions[-1] != pred and pred == 0): #One accidental\n",
    "                                if(X_train_2prev[name].iloc[i] > min_tre and name not in low_obs):\n",
    "                                    pred = 1\n",
    "                                elif(X_train_2prev[name].iloc[i] < max_tre and name in low_obs):\n",
    "                                    pred = 1\n",
    "                            elif(predictions[-2] != pred and predictions[-1] != pred and pred == 1): #One accidental smaller before\n",
    "                                if(X_train_2prev[name].iloc[i] < max_tre and name not in low_obs):\n",
    "                                    pred = 0\n",
    "                                elif(X_train_2prev[name].iloc[i] > min_tre and name in low_obs):\n",
    "                                    pred = 0\n",
    "\n",
    "\n",
    "                        if(y_train[i] == pred):\n",
    "                            correct += 1 \n",
    "                        else:\n",
    "                            wrong += 1\n",
    "                            if (wrong > best_wrong):\n",
    "                                break\n",
    "                        predictions.append(pred)\n",
    "                if (correct > best_correct):\n",
    "                    best_correct = correct\n",
    "                    best_wrong = wrong\n",
    "                    pred_max = predictions\n",
    "        printmd(\"**\" + name + \"**\")\n",
    "        print (\"Quantile 0.95: \" + str(X_train[name].quantile(0.95)))\n",
    "        print (\"Quantile 0.05: \" + str(X_train[name].quantile(0.05)))\n",
    "        print (str(best_correct) + \" out of \" + str(X_train.shape[0]))\n",
    "        print (\"Accuracy: \" + str(round(best_correct/X_train.shape[0] * 100, 2)) +\"%\")\n",
    "        feature_acc += [round(best_correct/X_train.shape[0] * 100, 2)]\n",
    "    feature_acc_all.append(feature_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Selecting features based on cyclic periods accuracy</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selected = ['0.1quant_accel_x_ins', #lower\n",
    "'0.1quant_accel_y', #lower\n",
    "'0.1quant_accel_z_ins', #lower\n",
    "'0.25quant_accel_x_ins', #lower\n",
    "'0.25quant_accel_y', #lower\n",
    "'0.25quant_accel_z_ins', #lower\n",
    "'0.75quant_accel_y', #lower\n",
    "'0.75quant_accel_z_ins', #lower\n",
    "'0.9quant_accel_y_exp', #lower\n",
    "'0.9quant_accel_z_ins', #lower\n",
    "'max_accel_y', #lower\n",
    "'mean_accel_y', #lower\n",
    "'mean_accel_x_ins', #lower\n",
    "'mean_accel_z_ins', #lower\n",
    "'median_accel_x_ins', #lower\n",
    "'median_accel_y', #lower\n",
    "'median_accel_z_ins', #lower\n",
    "'min-mean_accel_z', #higher\n",
    "'min_accel_x_ins', #lower\n",
    "'min_accel_y', #lower\n",
    "'min_accel_z_ins', #lower\n",
    "'std_accel_x_ins'] #higher]\n",
    "\n",
    "best_ft, best_val, best_tr, best_val_cyc, best_tr_cyc = [], 0, 0, 0, 0\n",
    "period_low, period_high = 3, 4\n",
    "for name in selected:\n",
    "    \n",
    "    pred = 1\n",
    "\n",
    "    X_set_2prev = ratios_2prev\n",
    "    X_set_3prev = ratios_3prev\n",
    "    max_best, min_best, best_correct = 0, 0, 0\n",
    "    max_set = np.linspace(1.0, X_set[name].quantile(0.95), num = 100)\n",
    "    min_set = np.linspace(X_set[name].quantile(0.05), 1.0, num = 100)\n",
    "\n",
    "    \n",
    "     #New only cyclic\n",
    "    length = 0\n",
    "    j = 0\n",
    "    on = 0\n",
    "    prev_index = 0\n",
    "    cyclic_j = []\n",
    "    for i in np.asarray(X_set.index):\n",
    "        if (Y_set[j] == 1):\n",
    "            cl = Y_set[j]\n",
    "            start = 1\n",
    "            while (cl == 1 and j-start >= 0):\n",
    "                cl = Y_set[j-start]\n",
    "                start += 1\n",
    "            start = j - start + 2\n",
    "            if (j - start >= period_low):\n",
    "                on = 1\n",
    "            else:\n",
    "                on = 0\n",
    "        else:\n",
    "            if (on == 1):\n",
    "                cl = Y_set[j]\n",
    "                end = 1\n",
    "                while cl == 0 and len(Y_set) > j+end:\n",
    "                    cl = Y_set[j+end]\n",
    "                    end += 1\n",
    "                end = j + end - 1\n",
    "                if (end -j > period_high):\n",
    "                    end = j+period_high\n",
    "                if (j - start > period_high):\n",
    "                    start = j-period_high\n",
    "                if((cannula[j].max()-cannula[j].min())/(cannula[j-1].max()-cannula[j-1].min()) > 1.5 and \n",
    "                   (cannula[j].max()-cannula[j].min())/(cannula[j-2].max()-cannula[j-2].min()) > 1.5 and\n",
    "                   (cannula[j].max()-cannula[j].min())/(cannula[j-3].max()-cannula[j-3].min()) > 1.5 and\n",
    "                   period_low <= end -j and period_low <= j-start):\n",
    "                    cyclic_j = cyclic_j + list(range(start, end))\n",
    "                on = 0\n",
    "        j += 1\n",
    "    for max_tre in max_set:\n",
    "        for min_tre in min_set:\n",
    "            correct, wrong = 0, 0\n",
    "            predictions = []\n",
    "            for i, ratio in enumerate(X_set[name]):\n",
    "                    if (ratio > max_tre):\n",
    "                        if name in low_obs:  \n",
    "                            pred = 0\n",
    "                        else: pred = 1\n",
    "                    elif(ratio < min_tre): \n",
    "                        if name in low_obs: \n",
    "                            pred = 1\n",
    "                        else: pred = 0\n",
    "                    if (len(predictions) > 2):\n",
    "#                                 if(predictions[-2] == pred and predictions[-1] == pred and pred == 1): #Slowly decreasing obstruction range -> normal\n",
    "#                                     if(X_set_2prev[name].iloc[i] < min_tre and name not in low_obs):\n",
    "#                                         pred = 0\n",
    "#                                     elif(X_set_2prev[name].iloc[i] > max_tre and name in low_obs):\n",
    "#                                         pred = 0\n",
    "                        if(predictions[-2] == pred and predictions[-1] == pred and pred == 0): #Slowly increasing -> obstruction\n",
    "                            if(X_set_2prev[name].iloc[i] > max_tre and name not in low_obs):\n",
    "                                pred = 1\n",
    "                            elif(X_set_2prev[name].iloc[i] < min_tre and name in low_obs):\n",
    "                                pred = 1\n",
    "                        elif(predictions[-2] != pred and predictions[-1] != pred and pred == 0): #One accidental\n",
    "                            if(X_set_2prev[name].iloc[i] > min_tre and name not in low_obs):\n",
    "                                pred = 1\n",
    "                            elif(X_set_2prev[name].iloc[i] < max_tre and name in low_obs):\n",
    "                                pred = 1\n",
    "                        elif(predictions[-2] != pred and predictions[-1] != pred and pred == 1): #One accidental smaller before\n",
    "                            if(X_set_2prev[name].iloc[i] < max_tre and name not in low_obs):\n",
    "                                pred = 0\n",
    "                            elif(X_set_2prev[name].iloc[i] > min_tre and name in low_obs):\n",
    "                                pred = 0\n",
    "\n",
    "\n",
    "                    if(Y_set[i] == pred and i in cyclic_j):\n",
    "                        correct += 1 \n",
    "                    predictions.append(pred)\n",
    "            if (correct > best_correct):\n",
    "                best_correct = correct\n",
    "                best_wrong = wrong\n",
    "                pred_max = predictions\n",
    "    printmd(\"**\" + name + \"**\")\n",
    "    print (str(best_correct) + \" out of \" + str(len(cyclic_j)))\n",
    "    print (\"Accuracy: \" + str(round(best_correct/len(cyclic_j) * 100, 2)) +\"%\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(feature_acc_all)\n",
    "for i, feat in enumerate(feature_acc_all):\n",
    "    print(\"Feature: \" + selected[i])\n",
    "    print(\"Accuracy: \" + str(round(np.mean(feat), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
